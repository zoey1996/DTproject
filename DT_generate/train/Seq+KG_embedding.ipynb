{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7f1aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/cxh/anaconda3/envs/DTproject/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "from utils import set_seed\n",
    "import numpy as np\n",
    "import wandb\n",
    "import math\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "from model import GPT, GPTConfig\n",
    "from trainer import Trainer, TrainerConfig\n",
    "\n",
    "from seq_kg_embedd import SmilesDataset\n",
    "import selfies as sf\n",
    "from PyBioMed.PyProtein import CTD\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f659da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "run_name = \"Transport_seq_KG_embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd2182a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzoey_chen\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/cxh/DTproject/DT_generate/train/wandb/run-20220611_184408-gkb4xxi3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/zoey_chen/DTproject/runs/gkb4xxi3\" target=\"_blank\">Transport_seq_KG_embedding</a></strong> to <a href=\"https://wandb.ai/zoey_chen/DTproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/zoey_chen/DTproject/runs/gkb4xxi3?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1ad275aeb8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"DTproject\", name=run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f33943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/chemb_drug_selfies.csv')\n",
    "data = data.dropna(axis=0).reset_index(drop=True)\n",
    "data.columns = data.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c82f553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>selfies</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_Q96A29</td>\n",
       "      <td>['[C]', '[C@@H1]', '[O]', '[C@H1]', '[Branch2]...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_P08183</td>\n",
       "      <td>['[C]', '[C]', '[Branch1]', '[C]', '[C]', '[O]...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_Q9Y6L6</td>\n",
       "      <td>['[C]', '[O]', '[C@@H1]', '[C]', '[C@H1]', '[B...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt                                            selfies  split\n",
       "0  dt_Q96A29  ['[C]', '[C@@H1]', '[O]', '[C@H1]', '[Branch2]...  train\n",
       "1  dt_P08183  ['[C]', '[C]', '[Branch1]', '[C]', '[C]', '[O]...  train\n",
       "2  dt_Q9Y6L6  ['[C]', '[O]', '[C@@H1]', '[C]', '[C@H1]', '[B...  train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(axis=0).reset_index(drop=True)\n",
    "data.head(3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d9cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_seq = pd.read_csv(\"../datasets/transport_pro_seq.txt\",sep='\\t')\n",
    "pro_seq = pro_seq.dropna(axis=0).reset_index(drop=True)\n",
    "pro_seq = pro_seq.rename(columns={\"uniprot_id\":\"dt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4e9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data = pd.merge(data,pro_seq,how=\"right\",on=\"dt\")\n",
    "merge_data = merge_data.dropna(axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e4fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_rescal_em = pd.read_csv(\"../datasets/kg_embedding/RESCAL_entity_embedding.csv\")\n",
    "\n",
    "merge_data2 = pd.merge(merge_data,entity_rescal_em,how=\"right\",left_on=\"dt\",right_on=\"ent_name\")\n",
    "merge_data2 = merge_data2.dropna(axis=0).reset_index(drop=True)\n",
    "merge_data2.drop(columns=['ent_name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436d1481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>selfies</th>\n",
       "      <th>split</th>\n",
       "      <th>seq</th>\n",
       "      <th>ent_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_Q13183</td>\n",
       "      <td>['[O]', '.', '[O]', '.', '[O]', '.', '[O]', '....</td>\n",
       "      <td>train</td>\n",
       "      <td>MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...</td>\n",
       "      <td>[-0.1436040699481964, -0.08548112958669662, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dt_Q13183</td>\n",
       "      <td>['[O]', '[=C]', '[Branch1]', '[C]', '[O]', '[C...</td>\n",
       "      <td>train</td>\n",
       "      <td>MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...</td>\n",
       "      <td>[-0.1436040699481964, -0.08548112958669662, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_Q13183</td>\n",
       "      <td>['[O]', '[=S]', '[=Branch1]', '[C]', '[=O]', '...</td>\n",
       "      <td>train</td>\n",
       "      <td>MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...</td>\n",
       "      <td>[-0.1436040699481964, -0.08548112958669662, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dt_Q13183</td>\n",
       "      <td>['[O]', '[=S]', '[=Branch1]', '[C]', '[=O]', '...</td>\n",
       "      <td>train</td>\n",
       "      <td>MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...</td>\n",
       "      <td>[-0.1436040699481964, -0.08548112958669662, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dt_Q13183</td>\n",
       "      <td>['[O]', '[=S]', '[=Branch1]', '[C]', '[=O]', '...</td>\n",
       "      <td>train</td>\n",
       "      <td>MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...</td>\n",
       "      <td>[-0.1436040699481964, -0.08548112958669662, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt                                            selfies  split  \\\n",
       "0  dt_Q13183  ['[O]', '.', '[O]', '.', '[O]', '.', '[O]', '....  train   \n",
       "1  dt_Q13183  ['[O]', '[=C]', '[Branch1]', '[C]', '[O]', '[C...  train   \n",
       "2  dt_Q13183  ['[O]', '[=S]', '[=Branch1]', '[C]', '[=O]', '...  train   \n",
       "3  dt_Q13183  ['[O]', '[=S]', '[=Branch1]', '[C]', '[=O]', '...  train   \n",
       "4  dt_Q13183  ['[O]', '[=S]', '[=Branch1]', '[C]', '[=O]', '...  train   \n",
       "\n",
       "                                                 seq  \\\n",
       "0  MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...   \n",
       "1  MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...   \n",
       "2  MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...   \n",
       "3  MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...   \n",
       "4  MATCWQALWAYRSYLIVFFVPILLLPLPILVPSKEAYCAYAIILMA...   \n",
       "\n",
       "                                       ent_embedding  \n",
       "0  [-0.1436040699481964, -0.08548112958669662, -0...  \n",
       "1  [-0.1436040699481964, -0.08548112958669662, -0...  \n",
       "2  [-0.1436040699481964, -0.08548112958669662, -0...  \n",
       "3  [-0.1436040699481964, -0.08548112958669662, -0...  \n",
       "4  [-0.1436040699481964, -0.08548112958669662, -0...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7c63a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52883\n",
      "13221\n"
     ]
    }
   ],
   "source": [
    "#Get selfies train and validation datasets\n",
    "\n",
    "train_data = merge_data2[merge_data2['split'] == 'train'].reset_index(drop=True)\n",
    "val_data = merge_data2[merge_data2['split'] == 'test'].reset_index(drop=True)\n",
    "\n",
    "selfies_list = list(train_data['selfies'])\n",
    "vselfies_list = list(val_data['selfies'])\n",
    "\n",
    "print(len(selfies_list))\n",
    "print(len(vselfies_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d2acbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "#Get All charsets from datasets\n",
    "\n",
    "from torchtext.legacy import data as d\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "\n",
    "all_selfies = data['selfies'].to_list()\n",
    "BLANK_WORD = \"<blank>\"\n",
    "tokenizer = lambda x: x.split()\n",
    "TGT = d.Field(tokenize=tokenizer,pad_token=BLANK_WORD)\n",
    "src = []\n",
    "src_len = []\n",
    "for i in all_selfies:\n",
    "    i = i[2:-2].replace(\"\\\\\\\\\",\"\\\\\")\n",
    "    src.append(i.split(\"', '\"))\n",
    "    src_len.append(len(i.split(\"', '\")))\n",
    "\n",
    "TGT.build_vocab(src)\n",
    "\n",
    "\n",
    "whole_string = []\n",
    "for k in TGT.vocab.stoi.keys():\n",
    "    whole_string.append(k)\n",
    "print(len(whole_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04b9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get charsets\n",
    "stoi = json.load(open(f'../datasets/drug_selfies_stoi.json', 'r'))\n",
    "itos = dict(zip(stoi.values(), stoi.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba139ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treat selfies as inputs of equal length to guarantee that the input model does not have dimensional problems\n",
    "\n",
    "max_len = max(src_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dee7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies = [] \n",
    "BLANK_WORD = '<blank>'\n",
    "for s in selfies_list:\n",
    "    s = eval(s)\n",
    "    while len(s) < max_len+1:   #以防末尾信息丢失\n",
    "        s.append(BLANK_WORD)\n",
    "    \n",
    "    selfies.append(s)\n",
    "    \n",
    "vselfies = [] \n",
    "BLANK_WORD = '<blank>'\n",
    "for vs in vselfies_list:\n",
    "    vs = eval(vs)\n",
    "    while len(vs) < max_len+1:  #以防末尾信息丢失\n",
    "        vs.append(BLANK_WORD)\n",
    "    \n",
    "    vselfies.append(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72fe272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain protein sequence conditions\n",
    "\n",
    "pro = train_data[\"seq\"]\n",
    "vpro = val_data[\"seq\"]\n",
    "\n",
    "embedding = train_data[\"ent_embedding\"]\n",
    "vembedding = val_data[\"ent_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d792a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 52883 smiles, 152 unique characters.\n",
      "data has 13221 smiles, 152 unique characters.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SmilesDataset(selfies,whole_string,stoi,itos,embedding,max_len,aug_prob=0,pro=pro)\n",
    "valid_dataset = SmilesDataset(vselfies,whole_string,stoi,itos,vembedding,max_len,aug_prob=0,pro=vpro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cee8df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_len = 947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc247ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layer = 8\n",
    "n_head = 8\n",
    "n_embd = 256\n",
    "lstm_layers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "118d722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mconf = GPTConfig(train_dataset.vocab_size, train_dataset.max_len, pro_len=pro_len,  # args.num_props,\n",
    "                        n_layer=n_layer, n_head=n_head, n_embd=n_embd,\n",
    "                        lstm=False, lstm_layers=lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f71bfc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(mconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7759de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 10\n",
    "batch_size = 16\n",
    "learning_rate = 6e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ad6e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tconf = TrainerConfig(max_epochs=max_epochs, batch_size=batch_size, \n",
    "                      learning_rate=learning_rate,\n",
    "                      lr_decay=True, warmup_tokens=0.1*len(train_data)*max_len, \n",
    "                      final_tokens= max_epochs*len(train_data)*max_len,\n",
    "                      num_workers=0, \n",
    "                      ckpt_path=f'../result/models/{run_name}.pt', \n",
    "                      block_size=train_dataset.max_len, generate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f147ee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, train_dataset, valid_dataset,\n",
    "                  tconf, train_dataset.stoi, train_dataset.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1022ccda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1 iter 3305: train loss 0.04914. lr 5.878964e-04: 100%|██████████| 3306/3306 [12:15<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 iter 3305: train loss 0.05534. lr 5.472984e-04: 100%|██████████| 3306/3306 [12:33<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 iter 3305: train loss 0.04312. lr 4.820944e-04: 100%|██████████| 3306/3306 [12:23<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 iter 3305: train loss 0.02616. lr 3.987721e-04: 100%|██████████| 3306/3306 [12:13<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 iter 3305: train loss 0.03184. lr 3.056219e-04: 100%|██████████| 3306/3306 [12:13<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 iter 3305: train loss 0.02703. lr 2.119125e-04: 100%|██████████| 3306/3306 [13:35<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 iter 3305: train loss 0.04490. lr 1.269677e-04: 100%|██████████| 3306/3306 [13:09<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 iter 3305: train loss 0.02254. lr 6.000000e-05: 100%|██████████| 3306/3306 [12:27<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 iter 3305: train loss 0.02978. lr 6.000000e-05: 100%|██████████| 3306/3306 [12:17<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 iter 3305: train loss 0.01465. lr 6.000000e-05: 100%|██████████| 3306/3306 [12:07<00:00,  4.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving at epoch 10\n"
     ]
    }
   ],
   "source": [
    "df = trainer.train(wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce0d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTproject",
   "language": "python",
   "name": "dtproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
